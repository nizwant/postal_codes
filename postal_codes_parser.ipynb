{
 "cells": [
  {
   "cell_type": "code",
   "source": "# CLEAN VERSION - Enhanced parser with multiline support\ndef enhanced_parse_pdf_clean(pdf_path: str, start_page: int = 1, end_page: int = None, \n                            max_unparsed: int = 10) -> tuple:\n    \"\"\"\n    Enhanced PDF parser that handles multiline records and tracks unparsed lines\n    Returns (parsed_records, unparsed_lines)\n    \"\"\"\n    results = []\n    unparsed_lines = []\n    \n    with pdfplumber.open(pdf_path) as pdf:\n        total_pages = len(pdf.pages)\n        \n        if end_page is None:\n            end_page = total_pages\n        \n        print(f\"Processing pages {start_page} to {end_page} of {total_pages}\")\n        \n        for page_num in range(start_page - 1, min(end_page, total_pages)):\n            page = pdf.pages[page_num]\n            current_page = page_num + 1\n            \n            print(f\"Processing page {current_page}...\", end=' ')\n            \n            try:\n                text = page.extract_text()\n                if not text:\n                    print(\"(no text)\")\n                    continue\n                \n                lines = text.split('\\\\n')\n                i = 0\n                page_records = 0\n                \n                while i < len(lines):\n                    line = clean_text(lines[i])\n                    \n                    if not line:\n                        i += 1\n                        continue\n                    \n                    # Skip header/footer lines\n                    skip_keywords = ['Poczta Polska', 'Strona', 'Copyright', 'PNA MiejscowoÅ›Ä‡ Ulica', 'CzÄ™Å›Ä‡ 1']\n                    if any(keyword in line for keyword in skip_keywords):\n                        i += 1\n                        continue\n                    \n                    # Try to parse using the fixed advanced parser if available\n                    parsed = None\n                    if 'fixed_advanced_parse_row' in globals():\n                        parsed = fixed_advanced_parse_row(line)\n                    else:\n                        parsed = improved_parse_row(line)\n                    \n                    if parsed:\n                        results.append(parsed)\n                        page_records += 1\n                        i += 1\n                    else:\n                        # Try multiline parsing\n                        if 'handle_multiline_records' in globals():\n                            parsed_multi, lines_consumed = handle_multiline_records(lines, i)\n                            \n                            if parsed_multi:\n                                results.append(parsed_multi)\n                                page_records += 1\n                                i += lines_consumed\n                            else:\n                                # This line couldn't be parsed\n                                parts = line.split()\n                                if parts and is_postal_code(parts[0]) and len(unparsed_lines) < max_unparsed:\n                                    unparsed_lines.append({\n                                        'page': current_page,\n                                        'line_number': i + 1,\n                                        'content': line\n                                    })\n                                i += 1\n                        else:\n                            # No multiline function available, just skip\n                            i += 1\n                \n                print(f\"({page_records} records)\")\n                \n            except Exception as e:\n                print(f\"Error on page {current_page}: {str(e)}\")\n                continue\n    \n    return results, unparsed_lines\n\n# Test the clean enhanced parser\nprint(\"Testing CLEAN enhanced parser...\")\ntry:\n    data_clean, unparsed_clean = enhanced_parse_pdf_clean(pdf_path, start_page=1, end_page=5)\n\n    print(f\"\\\\nâœ“ Successfully parsed: {len(data_clean)} records\")\n    print(f\"âœ— Could not parse: {len(unparsed_clean)} lines\")\n\n    if data_clean:\n        print(\"\\\\n=== SAMPLE PARSED RECORDS ===\")\n        for i, record in enumerate(data_clean[:10]):\n            print(f\"{i+1:2d}. {record['PNA']} | {record['MiejscowoÅ›Ä‡'][:15]:15} | {record['Ulica'][:15]:15} | {record['Gmina'][:12]:12} | {record['Powiat'][:12]:12} | {record['WojewÃ³dztwo']}\")\n        \n        # Look for Aleksandria records specifically\n        aleksandria_records = [r for r in data_clean if 'Aleksandria' in r.get('MiejscowoÅ›Ä‡', '')]\n        if aleksandria_records:\n            print(\"\\\\n=== ALEKSANDRIA RECORDS ===\")\n            for i, record in enumerate(aleksandria_records):\n                print(f\"{i+1}. {record['PNA']} | {record['MiejscowoÅ›Ä‡']} | '{record['Ulica']}' | '{record['Numery']}' | {record['Gmina']} | {record['Powiat']}\")\n\n    if unparsed_clean:\n        print(\"\\\\n=== UNPARSED LINES ===\")\n        for item in unparsed_clean[:5]:  # Show first 5\n            print(f\"Page {item['page']}: {item['content'][:80]}...\")\n            \nexcept Exception as e:\n    print(f\"Error running parser: {e}\")\n    import traceback\n    traceback.print_exc()\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the full parser with the fixed version\n",
    "def final_enhanced_parse_pdf(pdf_path: str, start_page: int = 1, end_page: int = None, \n",
    "                           max_unparsed: int = 10) -> tuple:\n",
    "    \\\"\\\"\\\"\n",
    "    Final enhanced PDF parser using the fixed advanced parsing logic\n",
    "    \\\"\\\"\\\"\n",
    "    results = []\n",
    "    unparsed_lines = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        total_pages = len(pdf.pages)\n",
    "        \n",
    "        if end_page is None:\n",
    "            end_page = total_pages\n",
    "        \n",
    "        print(f\\\"Processing pages {start_page} to {end_page} of {total_pages} (using FIXED parser)\\\")\n",
    "        \n",
    "        for page_num in range(start_page - 1, min(end_page, total_pages)):\n",
    "            page = pdf.pages[page_num]\n",
    "            current_page = page_num + 1\n",
    "            \n",
    "            print(f\\\"Processing page {current_page}...\\\", end=' ')\n",
    "            \n",
    "            try:\n",
    "                text = page.extract_text()\n",
    "                if not text:\n",
    "                    print(\\\"(no text)\\\")\n",
    "                    continue\n",
    "                \n",
    "                lines = text.split('\\\\n')\n",
    "                i = 0\n",
    "                page_records = 0\n",
    "                \n",
    "                while i < len(lines):\n",
    "                    line = clean_text(lines[i])\n",
    "                    \n",
    "                    if not line:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # Skip header/footer lines\n",
    "                    if any(keyword in line for keyword in ['Poczta Polska', 'Strona', 'Copyright', 'PNA MiejscowoÅ›Ä‡ Ulica', 'CzÄ™Å›Ä‡ 1']):\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # Try the fixed advanced parsing first\n",
    "                    parsed = fixed_advanced_parse_row(line)\n",
    "                    \n",
    "                    if parsed:\n",
    "                        results.append(parsed)\n",
    "                        page_records += 1\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        # Try multiline parsing as fallback\n",
    "                        parsed_multi, lines_consumed = handle_multiline_records(lines, i)\n",
    "                        \n",
    "                        if parsed_multi:\n",
    "                            # Re-process the multiline result with fixed parser\n",
    "                            combined_line = ' '.join([lines[i+j].strip() for j in range(lines_consumed)])\n",
    "                            reparsed = fixed_advanced_parse_row(combined_line)\n",
    "                            if reparsed:\n",
    "                                results.append(reparsed)\n",
    "                            else:\n",
    "                                results.append(parsed_multi)\n",
    "                            page_records += 1\n",
    "                            i += lines_consumed\n",
    "                        else:\n",
    "                            # This line couldn't be parsed\n",
    "                            parts = line.split()\n",
    "                            if parts and is_postal_code(parts[0]) and len(unparsed_lines) < max_unparsed:\n",
    "                                unparsed_lines.append({\n",
    "                                    'page': current_page,\n",
    "                                    'line_number': i + 1,\n",
    "                                    'content': line\n",
    "                                })\n",
    "                            i += 1\n",
    "                \n",
    "                print(f\\\"({page_records} records)\\\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\\\"Error on page {current_page}: {str(e)}\\\")\n",
    "                continue\n",
    "    \n",
    "    return results, unparsed_lines\n",
    "\n",
    "# Run the final parser\n",
    "print(\\\"Running FINAL enhanced parser...\\\")\\nfinal_data, final_unparsed = final_enhanced_parse_pdf(pdf_path, start_page=1, end_page=5)\n",
    "\n",
    "print(f\\\"\\\\nâœ“ Successfully parsed: {len(final_data)} records\\\")\n",
    "print(f\\\"âœ— Could not parse: {len(final_unparsed)} lines\\\")\n",
    "\n",
    "if final_data:\n",
    "    print(\\\"\\\\n=== FINAL PARSING RESULTS (first 15 records) ===\\\")\n",
    "    for i, record in enumerate(final_data[:15]):\n",
    "        print(f\\\"{i+1:2d}. {record['PNA']} | {record['MiejscowoÅ›Ä‡']:15} | {record['Ulica']:20} | {record['Numery']:20} | {record['Gmina']:15} | {record['Powiat']:12} | {record['WojewÃ³dztwo']}\\\")\n",
    "    \n",
    "    # Look for the specific Aleksandria records\n",
    "    aleksandria_fixed = [r for r in final_data if 'Aleksandria' in r.get('MiejscowoÅ›Ä‡', '') and 'Nowe Miasto' in r.get('Gmina', '')]\n",
    "    \n",
    "    if aleksandria_fixed:\n",
    "        print(\\\"\\\\nðŸŽ‰ ALEKSANDRIA RECORDS - FIXED:\\\")\n",
    "        for i, record in enumerate(aleksandria_fixed):\n",
    "            print(f\\\"{i+1}. {record['PNA']} | {record['MiejscowoÅ›Ä‡']} | '{record['Ulica']}' | '{record['Numery']}' | {record['Gmina']} | {record['Powiat']} | {record['WojewÃ³dztwo']}\\\")\n",
    "\n",
    "# Export the final results\n",
    "if final_data:\n",
    "    print(\\\"\\\\nExporting FINAL results...\\\")\n",
    "    final_df = export_to_csv(final_data, \\\"postal_codes_FINAL.csv\\\")\n",
    "\n",
    "if final_unparsed:\n",
    "    print(\\\"\\\\n=== FINAL UNPARSED LINES (still need help) ===\\\")\n",
    "    for item in final_unparsed:\n",
    "        print(f\\\"Page {item['page']}: {item['content'][:80]}...\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed advanced parser for compound names and complex addresses\n",
    "def fixed_advanced_parse_row(line: str) -> Optional[Dict[str, str]]:\n",
    "    \\\"\\\"\\\"\n",
    "    Fixed advanced parser that properly handles compound municipality names\n",
    "    \\\"\\\"\\\"\n",
    "    line = clean_text(line)\n",
    "    \n",
    "    if not line:\n",
    "        return None\n",
    "    \n",
    "    # Skip header/footer lines\n",
    "    skip_patterns = [\n",
    "        'Poczta Polska', 'Oficjalny Spis', 'Strona', 'Copyright', \n",
    "        'PNA MiejscowoÅ›Ä‡', 'CzÄ™Å›Ä‡ 1', 'miejscowoÅ›ci i ulic'\n",
    "    ]\n",
    "    \n",
    "    if any(pattern in line for pattern in skip_patterns):\n",
    "        return None\n",
    "    \n",
    "    parts = line.split()\n",
    "    \n",
    "    if len(parts) < 4:\n",
    "        return None\n",
    "    \n",
    "    # First part must be postal code\n",
    "    if not is_postal_code(parts[0]):\n",
    "        return None\n",
    "    \n",
    "    postal_code = parts[0]\n",
    "    \n",
    "    # Known voivodeships\n",
    "    voivodeships = [\n",
    "        'mazowieckie', 'Å›lÄ…skie', 'wielkopolskie', 'maÅ‚opolskie', 'lubelskie',\n",
    "        'podkarpackie', 'dolnoÅ›lÄ…skie', 'kujawsko-pomorskie', 'pomorskie',\n",
    "        'Å‚Ã³dzkie', 'zachodniopomorskie', 'lubuskie', 'podlaskie', 'Å›wiÄ™tokrzyskie',\n",
    "        'opolskie', 'warmiÅ„sko-mazurskie'\n",
    "    ]\n",
    "    \n",
    "    # Find voivodeship from the end\n",
    "    voivodeship = \\\"\\\"\n",
    "    voiv_idx = -1\n",
    "    \n",
    "    for i in range(len(parts) - 1, -1, -1):\n",
    "        if parts[i] in voivodeships:\n",
    "            voivodeship = parts[i]\n",
    "            voiv_idx = i\n",
    "            break\n",
    "        # Check compound voivodeships\n",
    "        if i > 0:\n",
    "            compound = parts[i-1] + '-' + parts[i]\n",
    "            if compound in voivodeships:\n",
    "                voivodeship = compound\n",
    "                voiv_idx = i - 1\n",
    "                break\n",
    "    \n",
    "    if not voivodeship or voiv_idx < 3:\n",
    "        return None\n",
    "    \n",
    "    # Powiat is just before voivodeship\n",
    "    if voivodeship.count('-') > 0:  # compound voivodeship\n",
    "        powiat_idx = voiv_idx - 1\n",
    "    else:\n",
    "        powiat_idx = voiv_idx - 1\n",
    "    \n",
    "    if powiat_idx < 2:\n",
    "        return None\n",
    "        \n",
    "    powiat = parts[powiat_idx]\n",
    "    \n",
    "    # Now we need to find where gmina ends and address begins\n",
    "    # Working backwards from powiat\n",
    "    remaining_parts = parts[1:powiat_idx]  # everything between postal code and powiat\n",
    "    \n",
    "    if len(remaining_parts) < 1:\n",
    "        return None\n",
    "    \n",
    "    # Common compound municipality names that we should keep together\n",
    "    compound_gminas = [\n",
    "        'Nowe Miasto', 'Stare Miasto', 'BiaÅ‚a Rawska', 'GÃ³ra Kalwaria',\n",
    "        'Nowa DÄ™ba', 'Stary SÄ…cz', 'Nowy DwÃ³r', 'BiaÅ‚a Podlaska',\n",
    "        'Pruszcz GdaÅ„ski', 'Nowy TomyÅ›l', 'Stary DzierzgoÅ„'\n",
    "    ]\n",
    "    \n",
    "    # Try to identify gmina (could be 1 or 2 words)\n",
    "    gmina = \\\"\\\"\n",
    "    gmina_word_count = 1\n",
    "    \n",
    "    # Check if last 2 words form a compound gmina\n",
    "    if len(remaining_parts) >= 2:\n",
    "        potential_compound = remaining_parts[-2] + ' ' + remaining_parts[-1]\n",
    "        if potential_compound in compound_gminas:\n",
    "            gmina = potential_compound\n",
    "            gmina_word_count = 2\n",
    "        else:\n",
    "            gmina = remaining_parts[-1]\n",
    "            gmina_word_count = 1\n",
    "    else:\n",
    "        gmina = remaining_parts[-1]\n",
    "        gmina_word_count = 1\n",
    "    \n",
    "    # Everything before gmina is address info (locality, street, numbers)\n",
    "    address_parts = remaining_parts[:-gmina_word_count]\n",
    "    \n",
    "    if len(address_parts) < 1:\n",
    "        return None\n",
    "    \n",
    "    # First address part is always locality\n",
    "    locality = address_parts[0]\n",
    "    \n",
    "    # Remaining parts are street and/or numbers\n",
    "    street = \\\"\\\"\n",
    "    numbers = \\\"\\\"\n",
    "    \n",
    "    if len(address_parts) > 1:\n",
    "        address_remaining = address_parts[1:]\n",
    "        \n",
    "        # Separate street from numbers\n",
    "        street_parts = []\n",
    "        number_parts = []\n",
    "        \n",
    "        # Strategy: collect everything that looks like numbers/ranges at the end\n",
    "        # Work backwards through address_remaining\n",
    "        collecting_numbers = False\n",
    "        \n",
    "        for i in range(len(address_remaining) - 1, -1, -1):\n",
    "            part = address_remaining[i]\n",
    "            \n",
    "            # Check if this looks like a number, range, or number modifier\n",
    "            if re.search(r'^\\\\d|\\\\d$|^\\\\d+[-,]|\\\\(.*\\\\)|^DK$', part) or part in [',', '-', 'n', 'p']:\n",
    "                number_parts.insert(0, part)  # Insert at beginning since we're going backwards\n",
    "                collecting_numbers = True\n",
    "            else:\n",
    "                # If we haven't started collecting numbers, it's street\n",
    "                # If we have started, we need to decide if this continues the numbers or is street\n",
    "                if not collecting_numbers:\n",
    "                    street_parts.insert(0, part)\n",
    "                else:\n",
    "                    # This could be part of a complex address - let's be conservative\n",
    "                    # and include it in numbers for now\n",
    "                    number_parts.insert(0, part)\n",
    "        \n",
    "        street = ' '.join(street_parts)\n",
    "        numbers = ' '.join(number_parts)\n",
    "    \n",
    "    return {\n",
    "        'PNA': postal_code,\n",
    "        'MiejscowoÅ›Ä‡': locality,\n",
    "        'Ulica': street,\n",
    "        'Numery': numbers,\n",
    "        'Gmina': gmina,\n",
    "        'Powiat': powiat,\n",
    "        'WojewÃ³dztwo': voivodeship\n",
    "    }\n",
    "\n",
    "# Test the fixed parser\n",
    "test_lines = [\n",
    "    \\\"05-192 Aleksandria 4-6, 7-9(n), 12-15 Nowe Miasto pÅ‚oÅ„ski mazowieckie\\\",\n",
    "    \\\"09-120 Aleksandria 8-10(p), 11, 31 Nowe Miasto pÅ‚oÅ„ski mazowieckie\\\",\n",
    "    \\\"83-440 Abisynia Karsin koÅ›cierski pomorskie\\\",\n",
    "    \\\"20-388 Abramowice KoÅ›cielne GÅ‚usk lubelski lubelskie\\\"\n",
    "]\n",
    "\n",
    "print(\\\"Testing FIXED advanced parser:\\\")\\nfor i, line in enumerate(test_lines):\n",
    "    print(f\\\"\\\\n{i+1}. Input: {line}\\\")\n",
    "    result = fixed_advanced_parse_row(line)\n",
    "    if result:\n",
    "        print(f\\\"   âœ“ {result['PNA']} | {result['MiejscowoÅ›Ä‡']:12} | {result['Ulica']:15} | {result['Numery']:20} | {result['Gmina']:15} | {result['Powiat']:12} | {result['WojewÃ³dztwo']}\\\")\n",
    "    else:\n",
    "        print(\\\"   âœ— Failed to parse\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1991665567.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\\"\\\"\\\"\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# Update the main parsing function to use the advanced parser\n",
    "def enhanced_parse_pdf_v2(pdf_path: str, start_page: int = 1, end_page: int = None, \n",
    "                         max_unparsed: int = 10) -> tuple:\n",
    "    results = []\n",
    "    unparsed_lines = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        total_pages = len(pdf.pages)\n",
    "        \n",
    "        if end_page is None:\n",
    "            end_page = total_pages\n",
    "        \n",
    "        print(f\\\"Processing pages {start_page} to {end_page} of {total_pages} (using advanced parser v2)\\\")\n",
    "        \n",
    "        for page_num in range(start_page - 1, min(end_page, total_pages)):\n",
    "            page = pdf.pages[page_num]\n",
    "            current_page = page_num + 1\n",
    "            \n",
    "            print(f\\\"Processing page {current_page}...\\\", end=' ')\n",
    "            \n",
    "            try:\n",
    "                text = page.extract_text()\n",
    "                if not text:\n",
    "                    print(\\\"(no text)\\\")\n",
    "                    continue\n",
    "                \n",
    "                lines = text.split('\\\\n')\n",
    "                i = 0\n",
    "                page_records = 0\n",
    "                \n",
    "                while i < len(lines):\n",
    "                    line = clean_text(lines[i])\n",
    "                    \n",
    "                    if not line:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # Skip header/footer lines\n",
    "                    if any(keyword in line for keyword in ['Poczta Polska', 'Strona', 'Copyright', 'PNA MiejscowoÅ›Ä‡ Ulica', 'CzÄ™Å›Ä‡ 1']):\\n                        i += 1\\n                        continue\\n                    \\n                    # Try advanced parsing first\\n                    parsed = advanced_parse_row(line)\\n                    \\n                    if parsed:\\n                        results.append(parsed)\\n                        page_records += 1\\n                        i += 1\\n                    else:\\n                        # Try multiline parsing\\n                        parsed_multi, lines_consumed = handle_multiline_records(lines, i)\\n                        \\n                        if parsed_multi:\\n                            results.append(parsed_multi)\\n                            page_records += 1\\n                            i += lines_consumed\\n                        else:\\n                            # This line couldn't be parsed\\n                            parts = line.split()\\n                            if parts and is_postal_code(parts[0]) and len(unparsed_lines) < max_unparsed:\\n                                unparsed_lines.append({\\n                                    'page': current_page,\\n                                    'line_number': i + 1,\\n                                    'content': line\\n                                })\\n                            i += 1\\n                \\n                print(f\\\"({page_records} records)\\\")\\n                \\n            except Exception as e:\\n                print(f\\\"Error on page {current_page}: {str(e)}\\\")\\n                continue\\n    \\n    return results, unparsed_lines\\n\\n# Re-run the parser with the improved version\\nprint(\\\"Re-running with advanced parser v2...\\\")\\ndata_v2, unparsed_v2 = enhanced_parse_pdf_v2(pdf_path, start_page=1, end_page=5)\\n\\nprint(f\\\"\\\\nâœ“ Successfully parsed: {len(data_v2)} records\\\")\\nprint(f\\\"âœ— Could not parse: {len(unparsed_v2)} lines\\\")\\n\\nif data_v2:\\n    print(\\\"\\\\n=== IMPROVED PARSING RESULTS ===\\\")\\n    \\n    # Look specifically for the Aleksandria records\\n    aleksandria_records = [r for r in data_v2 if r['MiejscowoÅ›Ä‡'] == 'Aleksandria' and r['Gmina'].startswith('Nowe')]\\n    \\n    if aleksandria_records:\\n        print(\\\"\\\\nAleksandria records (fixed):\\\")\\n        for i, record in enumerate(aleksandria_records):\\n            print(f\\\"{i+1}. {record['PNA']} | {record['MiejscowoÅ›Ä‡']:15} | {record['Ulica']:20} | {record['Numery']:20} | {record['Gmina']:15} | {record['Powiat']:12} | {record['WojewÃ³dztwo']}\\\")\\n    \\n    print(f\\\"\\\\nFirst 10 records overall:\\\")\\n    for i, record in enumerate(data_v2[:10]):\\n        print(f\\\"{i+1:2d}. {record['PNA']} | {record['MiejscowoÅ›Ä‡'][:15]:15} | {record['Ulica'][:15]:15} | {record['Numery'][:15]:15} | {record['Gmina'][:12]:12} | {record['Powiat'][:12]:12} | {record['WojewÃ³dztwo']}\\\")\\n\\n# Compare improvements\\nif len(data_v2) > len(data):\\n    print(f\\\"\\\\nðŸŽ‰ Improvement: {len(data_v2) - len(data)} more records parsed successfully!\\\")\\nelif len(unparsed_v2) < len(unparsed):\\n    print(f\\\"\\\\nðŸŽ‰ Improvement: {len(unparsed) - len(unparsed_v2)} fewer unparsed lines!\\\")\\n\\n# Export the improved results\\nif data_v2:\\n    print(\\\"\\\\nExporting improved results...\\\")\\n    df_v2 = export_to_csv(data_v2, \\\"postal_codes_sample_v2.csv\\\")\\n    \\nif unparsed_v2:\\n    print(\\\"\\\\n=== REMAINING UNPARSED LINES ===\\\")\\n    for item in unparsed_v2:\\n        print(f\\\"Page {item['page']}: {item['content'][:100]}...\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved parser to handle complex address ranges\n",
    "def advanced_parse_row(line: str) -> Optional[Dict[str, str]]:\n",
    "    \\\"\\\"\\\"\n",
    "    Advanced row parsing that better handles complex number ranges and compound names\n",
    "    \\\"\\\"\\\"\n",
    "    line = clean_text(line)\\n    \n",
    "    if not line:\n",
    "        return None\n",
    "    \n",
    "    # Skip obvious non-data lines\n",
    "    skip_patterns = [\n",
    "        'Poczta Polska', 'Oficjalny Spis', 'Strona', 'Copyright', \n",
    "        'PNA MiejscowoÅ›Ä‡', 'CzÄ™Å›Ä‡ 1', 'miejscowoÅ›ci i ulic'\n",
    "    ]\n",
    "    \n",
    "    if any(pattern in line for pattern in skip_patterns):\n",
    "        return None\n",
    "    \n",
    "    parts = line.split()\n",
    "    \n",
    "    if len(parts) < 4:\n",
    "        return None\n",
    "    \n",
    "    # First part must be postal code\n",
    "    if not is_postal_code(parts[0]):\n",
    "        return None\n",
    "    \n",
    "    postal_code = parts[0]\n",
    "    \n",
    "    # Known voivodeships (including compound ones)\n",
    "    voivodeships = [\n",
    "        'mazowieckie', 'Å›lÄ…skie', 'wielkopolskie', 'maÅ‚opolskie', 'lubelskie',\n",
    "        'podkarpackie', 'dolnoÅ›lÄ…skie', 'kujawsko-pomorskie', 'pomorskie',\n",
    "        'Å‚Ã³dzkie', 'zachodniopomorskie', 'lubuskie', 'podlaskie', 'Å›wiÄ™tokrzyskie',\n",
    "        'opolskie', 'warmiÅ„sko-mazurskie'\n",
    "    ]\n",
    "    \n",
    "    # Find voivodeship\n",
    "    voivodeship = \\\"\\\"\n",
    "    voiv_idx = -1\n",
    "    \n",
    "    # Check from end backwards\n",
    "    for i in range(len(parts) - 1, -1, -1):\n",
    "        if parts[i] in voivodeships:\n",
    "            voivodeship = parts[i]\n",
    "            voiv_idx = i\n",
    "            break\n",
    "        # Check compound voivodeships\n",
    "        if i > 0:\n",
    "            compound = parts[i-1] + '-' + parts[i]\n",
    "            if compound in voivodeships:\n",
    "                voivodeship = compound\n",
    "                voiv_idx = i - 1\n",
    "                break\n",
    "    \n",
    "    if not voivodeship or voiv_idx < 3:\n",
    "        return None\n",
    "    \n",
    "    # Extract powiat and gmina (should be just before voivodeship)\n",
    "    remaining_parts = parts[1:voiv_idx]  # Everything between postal code and voivodeship\n",
    "    \n",
    "    if len(remaining_parts) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Powiat is the last part before voivodeship\n",
    "    powiat = remaining_parts[-1]\n",
    "    \n",
    "    # Gmina could be compound (e.g., \\\"Nowe Miasto\\\")\n",
    "    # We need to identify where the locality/street/numbers end and gmina begins\n",
    "    \n",
    "    # Strategy: Look for common patterns in gmina names and number patterns\n",
    "    gmina_parts = []\n",
    "    address_parts = remaining_parts[:-1]  # Everything except powiat\n",
    "    \n",
    "    # Common compound municipality names\n",
    "    compound_municipalities = [\n",
    "        \\\"Nowe Miasto\\\", \\\"Stare Miasto\\\", \\\"BiaÅ‚a Rawska\\\", \\\"GÃ³ra Kalwaria\\\",\\        \\\"Nowa DÄ™ba\\\", \\\"Stary SÄ…cz\\\", \\\"Nowy DwÃ³r\\\", \\\"BiaÅ‚a Podlaska\\\"\n",
    "    ]\n",
    "    \n",
    "    # Check if the last few parts form a compound municipality name\n",
    "    gmina = \\\"\\\"\n",
    "    gmina_start_idx = len(address_parts)  # Default: no gmina found in address_parts\n",
    "    \n",
    "    # Try 2-word compound names first\n",
    "    if len(address_parts) >= 2:\n",
    "        potential_2word = address_parts[-2] + \\\" \\\" + address_parts[-1]\n",
    "        if potential_2word in compound_municipalities:\n",
    "            gmina = potential_2word\n",
    "            gmina_start_idx = len(address_parts) - 2\n",
    "        else:\n",
    "            # Try single word\n",
    "            gmina = address_parts[-1]\n",
    "            gmina_start_idx = len(address_parts) - 1\n",
    "    else:\n",
    "        gmina = address_parts[-1]\n",
    "        gmina_start_idx = len(address_parts) - 1\n",
    "    \n",
    "    # Everything before gmina is locality, street, and numbers\n",
    "    location_parts = address_parts[:gmina_start_idx]\n",
    "    \n",
    "    if not location_parts:\n",
    "        return None\n",
    "    \n",
    "    # First part is always locality\n",
    "    locality = location_parts[0]\n",
    "    \n",
    "    # Separate street from numbers in remaining parts\n",
    "    street_parts = []\n",
    "    number_parts = []\n",
    "    \n",
    "    # Look for number patterns: digits, ranges, parenthetical notes\n",
    "    number_indicators = re.compile(r'[0-9]|[()n,p-]|DK')\n",
    "    \n",
    "    collecting_numbers = False\n",
    "    for part in location_parts[1:]:\n",
    "        # If we find number indicators, start collecting numbers\n",
    "        if number_indicators.search(part):\n",
    "            collecting_numbers = True\n",
    "            number_parts.append(part)\n",
    "        else:\n",
    "            # If not collecting numbers yet, it's part of street name\n",
    "            if not collecting_numbers:\n",
    "                street_parts.append(part)\n",
    "            else:\n",
    "                # This could be a continuation of address (like \\\"Nowe\\\" in \\\"Nowe Miasto\\\")\n",
    "                # But since we're already collecting numbers, it might be part of complex address\n",
    "                number_parts.append(part)\n",
    "    \n",
    "    return {\n",
    "        'PNA': postal_code,\n",
    "        'MiejscowoÅ›Ä‡': locality,\n",
    "        'Ulica': ' '.join(street_parts),\n",
    "        'Numery': ' '.join(number_parts),\n",
    "        'Gmina': gmina,\n",
    "        'Powiat': powiat,\n",
    "        'WojewÃ³dztwo': voivodeship\n",
    "    }\n",
    "\n",
    "# Test the advanced parser on the problematic records\n",
    "test_lines = [\n",
    "    \\\"05-192 Aleksandria 4-6, 7-9(n), 12-15 Nowe Miasto pÅ‚oÅ„ski mazowieckie\\\",\n",
    "    \\\"09-120 Aleksandria 8-10(p), 11, 31 Nowe Miasto pÅ‚oÅ„ski mazowieckie\\\"\n",
    "]\n",
    "\n",
    "print(\\\"Testing advanced parser on problematic records:\\\")\\nfor i, line in enumerate(test_lines):\n",
    "    print(f\\\"\\\\n{i+1}. Input: {line}\\\")\n",
    "    result = advanced_parse_row(line)\n",
    "    if result:\n",
    "        print(f\\\"   âœ“ PNA: {result['PNA']} | MiejscowoÅ›Ä‡: {result['MiejscowoÅ›Ä‡']} | Ulica: '{result['Ulica']}' | Numery: '{result['Numery']}' | Gmina: {result['Gmina']} | Powiat: {result['Powiat']} | Woj: {result['WojewÃ³dztwo']}\\\")\n",
    "    else:\n",
    "        print(\\\"   âœ— Failed to parse\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the full PDF (when ready)\\ndef process_full_pdf(pdf_path: str, output_file: str = \\\"complete_postal_codes.csv\\\", \\n                    batch_size: int = 50):\\n    \\\"\\\"\\\"\\n    Process the complete PDF in batches to avoid memory issues\\n    \\\"\\\"\\\"\\n    print(\\\"=== PROCESSING COMPLETE PDF ===\\\")\\n    print(\\\"This will process the entire PDF (could take several minutes)...\\\")\\n    \\n    response = input(\\\"Continue? (y/n): \\\").strip().lower()\\n    if response != 'y':\\n        print(\\\"Cancelled.\\\")\\n        return\\n    \\n    all_records = []\\n    all_unparsed = []\\n    \\n    with pdfplumber.open(pdf_path) as pdf:\\n        total_pages = len(pdf.pages)\\n        print(f\\\"Total pages to process: {total_pages}\\\")\\n        \\n        # Process in batches\\n        for start_page in range(1, total_pages + 1, batch_size):\\n            end_page = min(start_page + batch_size - 1, total_pages)\\n            \\n            print(f\\\"\\\\nProcessing batch: pages {start_page}-{end_page}\\\")\\n            \\n            batch_records, batch_unparsed = enhanced_parse_pdf(\\n                pdf_path, start_page, end_page, max_unparsed=50\\n            )\\n            \\n            all_records.extend(batch_records)\\n            all_unparsed.extend(batch_unparsed)\\n            \\n            print(f\\\"Batch results: {len(batch_records)} parsed, {len(batch_unparsed)} unparsed\\\")\\n            print(f\\\"Total so far: {len(all_records)} records\\\")\\n            \\n            # Save intermediate results every few batches\\n            if len(all_records) % (batch_size * 3) == 0 or end_page == total_pages:\\n                temp_file = f\\\"temp_postal_codes_{len(all_records)}_records.csv\\\"\\n                export_to_csv(all_records, temp_file)\\n                print(f\\\"Saved intermediate results to {temp_file}\\\")\\n    \\n    # Final export\\n    print(f\\\"\\\\n=== FINAL RESULTS ===\\\")\\n    print(f\\\"Total records parsed: {len(all_records)}\\\")\\n    print(f\\\"Total unparsed lines: {len(all_unparsed)}\\\")\\n    \\n    if all_records:\\n        final_df = export_to_csv(all_records, output_file)\\n        \\n        # Save unparsed lines for manual review\\n        if all_unparsed:\\n            unparsed_df = pd.DataFrame(all_unparsed)\\n            unparsed_file = \\\"unparsed_lines.csv\\\"\\n            unparsed_df.to_csv(unparsed_file, index=False)\\n            print(f\\\"Saved {len(all_unparsed)} unparsed lines to {unparsed_file} for manual review\\\")\\n        \\n        return final_df, all_unparsed\\n    \\n    return None, all_unparsed\\n\\nprint(\\\"Full PDF processing function ready.\\\")\\nprint(\\\"\\\\nTo process the complete PDF, run:\\\")\\nprint(\\\"process_full_pdf('oficjalny_spis_pna_2025.pdf')\\\")\\nprint(\\\"\\\\nTo process just the sample (pages 3-22), run:\\\")\\nprint(\\\"enhanced_parse_pdf('pages_3_to_22.pdf', start_page=1, end_page=20)\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\\ndef export_to_csv(records: List[Dict[str, str]], output_file: str = \\\"polish_postal_codes.csv\\\"):\\n    \\\"\\\"\\\"Export parsed records to CSV file\\\"\\\"\\\"\\n    if not records:\\n        print(\\\"No records to export\\\")\\n        return\\n    \\n    df = pd.DataFrame(records)\\n    \\n    # Ensure all expected columns are present\\n    for col in COLUMNS:\\n        if col not in df.columns:\\n            df[col] = \\\"\\\"\\n    \\n    # Reorder columns to match expected structure\\n    df = df[COLUMNS]\\n    \\n    # Save to CSV\\n    df.to_csv(output_file, index=False, encoding='utf-8')\\n    \\n    print(f\\\"âœ“ Exported {len(records)} records to {output_file}\\\")\\n    print(f\\\"Columns: {', '.join(COLUMNS)}\\\")\\n    \\n    # Show some statistics\\n    print(f\\\"\\\\n=== EXPORT STATISTICS ===\\\")\\n    print(f\\\"Total records: {len(df)}\\\")\\n    print(f\\\"Unique postal codes: {df['PNA'].nunique()}\\\")\\n    print(f\\\"Unique voivodeships: {df['WojewÃ³dztwo'].nunique()}\\\")\\n    \\n    # Show voivodeship distribution\\n    voiv_counts = df['WojewÃ³dztwo'].value_counts()\\n    print(f\\\"\\\\nRecords per voivodeship:\\\")\\n    for voiv, count in voiv_counts.items():\\n        print(f\\\"  {voiv}: {count}\\\")\\n    \\n    return df\\n\\n# Export current data to CSV\\nif data:\\n    print(\\\"Exporting parsed data to CSV...\\\")\\n    df_export = export_to_csv(data, \\\"postal_codes_sample.csv\\\")\\n    \\n    print(f\\\"\\\\n=== SAMPLE OF EXPORTED DATA ===\\\")\\n    print(df_export.head(10).to_string(index=False))\\n    \\nelse:\\n    print(\\\"No data to export yet.\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive helper for unparsed records\n",
    "def help_parse_record(line: str) -> Optional[Dict[str, str]]:\\n    \\\"\\\"\\\"\\n    Interactive helper to manually parse problematic records\\n    \\\"\\\"\\\"\\n    print(f\\\"\\\\nHelp parse this line: {line}\\\")\\n    parts = line.strip().split()\\n    print(f\\\"Parts: {parts}\\\")\\n    \\n    try:\\n        # Let's try to identify patterns\\n        postal_code = \\\"\\\"\\n        locality = \\\"\\\"\\n        street = \\\"\\\"\\n        numbers = \\\"\\\"\\n        gmina = \\\"\\\"\\n        powiat = \\\"\\\"\\n        voivodeship = \\\"\\\"\\n        \\n        # Find postal code\\n        for i, part in enumerate(parts):\\n            if is_postal_code(part):\\n                postal_code = part\\n                remaining_parts = parts[i+1:]\\n                break\\n        \\n        if not postal_code:\\n            print(\\\"No valid postal code found\\\")\\n            return None\\n            \\n        print(f\\\"Postal code: {postal_code}\\\")\\n        print(f\\\"Remaining parts: {remaining_parts}\\\")\\n        \\n        # Try to find voivodeship\\n        voivodeships = [\\n            'mazowieckie', 'Å›lÄ…skie', 'wielkopolskie', 'maÅ‚opolskie', 'lubelskie',\\n            'podkarpackie', 'dolnoÅ›lÄ…skie', 'kujawsko-pomorskie', 'pomorskie',\\n            'Å‚Ã³dzkie', 'zachodniopomorskie', 'lubuskie', 'podlaskie', 'Å›wiÄ™tokrzyskie',\\n            'opolskie', 'warmiÅ„sko-mazurskie'\\n        ]\\n        \\n        voiv_idx = -1\\n        for i in range(len(remaining_parts) - 1, -1, -1):\\n            if remaining_parts[i] in voivodeships:\\n                voivodeship = remaining_parts[i]\\n                voiv_idx = i\\n                break\\n            # Check compound\\n            if i > 0:\\n                compound = remaining_parts[i-1] + '-' + remaining_parts[i]\\n                if compound in voivodeships:\\n                    voivodeship = compound\\n                    voiv_idx = i - 1\\n                    break\\n        \\n        if voivodeship:\\n            print(f\\\"Found voivodeship: {voivodeship} at position {voiv_idx}\\\")\\n            \\n            # Powiat and gmina should be before voivodeship\\n            if voiv_idx >= 2:\\n                powiat = remaining_parts[voiv_idx - 1]\\n                gmina = remaining_parts[voiv_idx - 2]\\n                print(f\\\"Inferred powiat: {powiat}, gmina: {gmina}\\\")\\n                \\n                # Everything before gmina is locality/street/numbers\\n                middle_parts = remaining_parts[:voiv_idx - 2]\\n                if middle_parts:\\n                    locality = middle_parts[0]\\n                    if len(middle_parts) > 1:\\n                        # Rest could be street and numbers\\n                        street_and_numbers = middle_parts[1:]\\n                        # Simple heuristic: if it contains digits, it's probably numbers\\n                        street_parts = []\\n                        number_parts = []\\n                        for part in street_and_numbers:\\n                            if re.search(r'\\\\d', part):\\n                                number_parts.append(part)\\n                            else:\\n                                if not number_parts:  # Only add to street if we haven't started numbers\\n                                    street_parts.append(part)\\n                        street = ' '.join(street_parts)\\n                        numbers = ' '.join(number_parts)\\n        \\n        result = {\\n            'PNA': postal_code,\\n            'MiejscowoÅ›Ä‡': locality,\\n            'Ulica': street,\\n            'Numery': numbers,\\n            'Gmina': gmina,\\n            'Powiat': powiat,\\n            'WojewÃ³dztwo': voivodeship\\n        }\\n        \\n        print(f\\\"Suggested parsing: {result}\\\")\\n        return result\\n        \\n    except Exception as e:\\n        print(f\\\"Error in manual parsing: {e}\\\")\\n        return None\\n\\n# Test manual parsing on unparsed records\\nif unparsed:\\n    print(\\\"\\\\n=== ATTEMPTING TO MANUALLY PARSE DIFFICULT RECORDS ===\\\")\\n    manual_results = []\\n    \\n    for item in unparsed[:3]:  # Try first 3 unparsed records\\n        print(f\\\"\\\\nTrying to parse from page {item['page']}: {item['content']}\\\")\\n        manual_parsed = help_parse_record(item['content'])\\n        if manual_parsed:\\n            manual_results.append(manual_parsed)\\n            print(\\\"âœ“ Successfully parsed manually\\\")\\n        else:\\n            print(\\\"âœ— Still couldn't parse - needs human help\\\")\\n    \\n    if manual_results:\\n        print(f\\\"\\\\nManually parsed {len(manual_results)} additional records!\\\")\\n        data.extend(manual_results)\\n        print(f\\\"Total records now: {len(data)}\\\")\\nelse:\\n    print(\\\"\\\\nNo unparsed records - great job!\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced parser with multiline support\n",
    "def enhanced_parse_pdf(pdf_path: str, start_page: int = 1, end_page: int = None, \n",
    "                      max_unparsed: int = 10) -> tuple:\n",
    "    \\\"\\\"\\\"\n",
    "    Enhanced PDF parser that handles multiline records and tracks unparsed lines\n",
    "    Returns (parsed_records, unparsed_lines)\n",
    "    \\\"\\\"\\\"\n",
    "    results = []\n",
    "    unparsed_lines = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        total_pages = len(pdf.pages)\n",
    "        \n",
    "        if end_page is None:\n",
    "            end_page = total_pages\n",
    "        \n",
    "        print(f\\\"Processing pages {start_page} to {end_page} of {total_pages}\\\")\\n        \\n        for page_num in range(start_page - 1, min(end_page, total_pages)):\\n            page = pdf.pages[page_num]\\n            current_page = page_num + 1\\n            \\n            print(f\\\"Processing page {current_page}...\\\", end=' ')\\n            \\n            try:\\n                text = page.extract_text()\\n                if not text:\\n                    print(\\\"(no text)\\\")\\n                    continue\\n                \\n                lines = text.split('\\\\n')\\n                i = 0\\n                page_records = 0\\n                \\n                while i < len(lines):\\n                    line = clean_text(lines[i])\\n                    \\n                    if not line:\\n                        i += 1\\n                        continue\\n                    \\n                    # Skip header/footer lines\\n                    if any(keyword in line for keyword in ['Poczta Polska', 'Strona', 'Copyright', 'PNA MiejscowoÅ›Ä‡ Ulica', 'CzÄ™Å›Ä‡ 1']):\\n                        i += 1\\n                        continue\\n                    \\n                    # Try simple parsing first\\n                    parsed = improved_parse_row(line)\\n                    \\n                    if parsed:\\n                        results.append(parsed)\\n                        page_records += 1\\n                        i += 1\\n                    else:\\n                        # Try multiline parsing\\n                        parsed_multi, lines_consumed = handle_multiline_records(lines, i)\\n                        \\n                        if parsed_multi:\\n                            results.append(parsed_multi)\\n                            page_records += 1\\n                            i += lines_consumed\\n                        else:\\n                            # This line couldn't be parsed\\n                            parts = line.split()\\n                            if parts and is_postal_code(parts[0]) and len(unparsed_lines) < max_unparsed:\\n                                unparsed_lines.append({\\n                                    'page': current_page,\\n                                    'line_number': i + 1,\\n                                    'content': line\\n                                })\\n                            i += 1\\n                \\n                print(f\\\"({page_records} records)\\\")\\n                \\n            except Exception as e:\\n                print(f\\\"Error on page {current_page}: {str(e)}\\\")\\n                continue\\n    \\n    return results, unparsed_lines\\n\\n# Test the enhanced parser\\nprint(\\\"Testing enhanced parser...\\\")\\ndata, unparsed = enhanced_parse_pdf(pdf_path, start_page=1, end_page=5)\\n\\nprint(f\\\"\\\\nâœ“ Successfully parsed: {len(data)} records\\\")\\nprint(f\\\"âœ— Could not parse: {len(unparsed)} lines\\\")\\n\\nif data:\\n    print(\\\"\\\\n=== SAMPLE PARSED RECORDS ===\\\")\\n    for i, record in enumerate(data[:10]):\\n        print(f\\\"{i+1:2d}. {record['PNA']} | {record['MiejscowoÅ›Ä‡'][:15]:15} | {record['Ulica'][:15]:15} | {record['Gmina'][:12]:12} | {record['Powiat'][:12]:12} | {record['WojewÃ³dztwo']}\\\")\\n\\nif unparsed:\\n    print(\\\"\\\\n=== UNPARSED LINES (need manual help) ===\\\")\\n    for item in unparsed:\\n        print(f\\\"Page {item['page']}, Line {item['line_number']}: {item['content'][:80]}...\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual parsing for problematic records\n",
    "def manual_parse_request(line: str, line_number: int = None, page_number: int = None):\n",
    "    \"\"\"\n",
    "    When we encounter a record that can't be automatically parsed,\n",
    "    this function will ask for manual input\n",
    "    \"\"\"\n",
    "    print(f\"\\\\n{'='*80}\")\n",
    "    if page_number:\n",
    "        print(f\"PARSING ISSUE - Page {page_number}, Line {line_number}\")\n",
    "    print(f\"Cannot automatically parse: {repr(line)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Try to give some hints about what we found\n",
    "    parts = line.strip().split()\n",
    "    if parts:\n",
    "        if is_postal_code(parts[0]):\n",
    "            print(f\"âœ“ Found postal code: {parts[0]}\")\n",
    "        else:\n",
    "            print(f\"âœ— First part doesn't look like postal code: {parts[0]}\")\n",
    "        \n",
    "        print(f\"Total parts found: {len(parts)}\")\n",
    "        print(f\"Parts: {parts}\")\n",
    "    \n",
    "    print(\\\"\\\\nPlease help identify the columns:\\\")\n",
    "    print(\\\"1. Postal Code (PNA): \\\")\n",
    "    print(\\\"2. Locality (MiejscowoÅ›Ä‡): \\\")\n",
    "    print(\\\"3. Street (Ulica): \\\")\n",
    "    print(\\\"4. Numbers (Numery): \\\")\n",
    "    print(\\\"5. Municipality (Gmina): \\\")\n",
    "    print(\\\"6. County (Powiat): \\\")\n",
    "    print(\\\"7. Voivodeship (WojewÃ³dztwo): \\\")\n",
    "    \n",
    "    # For now, return None - we'll handle this interactively\n",
    "    return None\n",
    "\n",
    "def handle_multiline_records(lines: List[str], start_idx: int) -> tuple:\n",
    "    \\\"\\\"\\\"\n",
    "    Handle records that span multiple lines (due to long city names, etc.)\n",
    "    Returns (parsed_record, number_of_lines_consumed)\n",
    "    \\\"\\\"\\\"\n",
    "    combined_line = lines[start_idx].strip()\n",
    "    lines_used = 1\n",
    "    \n",
    "    # Check if this line starts with a postal code\n",
    "    parts = combined_line.split()\n",
    "    if not parts or not is_postal_code(parts[0]):\n",
    "        return None, 0\n",
    "    \n",
    "    # If the line seems incomplete (too few parts), try combining with next line\n",
    "    if len(parts) < 6 and start_idx + 1 < len(lines):\n",
    "        next_line = lines[start_idx + 1].strip()\n",
    "        \n",
    "        # Only combine if next line doesn't start with postal code\n",
    "        next_parts = next_line.split()\n",
    "        if next_parts and not is_postal_code(next_parts[0]):\n",
    "            combined_line += \\\" \\\" + next_line\n",
    "            lines_used = 2\n",
    "            \n",
    "            # Check if we need a third line\n",
    "            if len(combined_line.split()) < 6 and start_idx + 2 < len(lines):\n",
    "                third_line = lines[start_idx + 2].strip()\n",
    "                third_parts = third_line.split()\n",
    "                if third_parts and not is_postal_code(third_parts[0]):\n",
    "                    combined_line += \\\" \\\" + third_line\n",
    "                    lines_used = 3\n",
    "    \n",
    "    # Try to parse the combined line\n",
    "    parsed = improved_parse_row(combined_line)\n",
    "    \n",
    "    return parsed, lines_used\n",
    "\n",
    "print(\\\"Advanced parsing functions defined\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polish Postal Codes PDF Parser\n",
    "\n",
    "This notebook parses the Polish postal codes PDF and converts it to CSV format.\n",
    "The PDF contains postal codes with address mappings in a structured table format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structure of our data\n",
    "COLUMNS = [\"PNA\", \"MiejscowoÅ›Ä‡\", \"Ulica\", \"Numery\", \"Gmina\", \"Powiat\", \"WojewÃ³dztwo\"]\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean extracted text by removing extra whitespace and newlines\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", text.strip())\n",
    "\n",
    "\n",
    "def is_postal_code(text: str) -> bool:\n",
    "    \"\"\"Check if text matches Polish postal code format (XX-XXX)\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    return bool(re.match(r\"^\\d{2}-\\d{3}$\", text.strip()))\n",
    "\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_positions(page):\n",
    "    \"\"\"Extract text with position information from a PDF page\"\"\"\n",
    "    chars = page.chars\n",
    "\n",
    "    # Group characters by approximate y-position (rows)\n",
    "    rows = {}\n",
    "    for char in chars:\n",
    "        y = round(char[\"y0\"], 1)  # Round to avoid small variations\n",
    "        if y not in rows:\n",
    "            rows[y] = []\n",
    "        rows[y].append(char)\n",
    "\n",
    "    # Sort rows by y-position (top to bottom)\n",
    "    sorted_rows = sorted(\n",
    "        rows.items(), key=lambda x: -x[0]\n",
    "    )  # Negative for top to bottom\n",
    "\n",
    "    return sorted_rows\n",
    "\n",
    "\n",
    "def parse_table_row(row_chars):\n",
    "    \"\"\"Parse a single table row into columns based on character positions\"\"\"\n",
    "    if not row_chars:\n",
    "        return None\n",
    "\n",
    "    # Sort characters by x-position (left to right)\n",
    "    row_chars.sort(key=lambda x: x[\"x0\"])\n",
    "\n",
    "    # Reconstruct text from characters\n",
    "    full_text = \"\".join([char[\"text\"] for char in row_chars])\n",
    "\n",
    "    # Skip header rows and empty rows\n",
    "    if not full_text.strip() or \"PNA\" in full_text or \"MiejscowoÅ›Ä‡\" in full_text:\n",
    "        return None\n",
    "\n",
    "    # Try to identify if this row starts with a postal code\n",
    "    words = full_text.split()\n",
    "    if not words or not is_postal_code(words[0]):\n",
    "        return None\n",
    "\n",
    "    return full_text\n",
    "\n",
    "\n",
    "print(\"Text extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row_columns(text_line: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"Parse a text line into structured columns\"\"\"\n",
    "    if not text_line or not text_line.strip():\n",
    "        return None\n",
    "\n",
    "    # Split the line into parts\n",
    "    parts = text_line.strip().split()\n",
    "\n",
    "    if (\n",
    "        len(parts) < 4\n",
    "    ):  # Need at least postal code, locality, gmina, powiat, voivodeship\n",
    "        return None\n",
    "\n",
    "    # First part should be postal code\n",
    "    if not is_postal_code(parts[0]):\n",
    "        return None\n",
    "\n",
    "    postal_code = parts[0]\n",
    "\n",
    "    # Last three parts are typically: gmina, powiat, wojewÃ³dztwo\n",
    "    voivodeship = parts[-1]\n",
    "    powiat = parts[-2]\n",
    "    gmina = parts[-3]\n",
    "\n",
    "    # Everything between postal code and last 3 parts is locality, street, numbers\n",
    "    middle_parts = parts[1:-3]\n",
    "\n",
    "    if not middle_parts:\n",
    "        return None\n",
    "\n",
    "    # First middle part is locality\n",
    "    locality = middle_parts[0]\n",
    "\n",
    "    # Try to separate street and numbers from remaining parts\n",
    "    street = \"\"\n",
    "    numbers = \"\"\n",
    "\n",
    "    if len(middle_parts) > 1:\n",
    "        # Look for parts that look like house numbers (contain digits, ranges, etc.)\n",
    "        street_parts = []\n",
    "        number_parts = []\n",
    "\n",
    "        for part in middle_parts[1:]:\n",
    "            # If part contains digits or typical number patterns, treat as numbers\n",
    "            if re.search(r\"\\d\", part) or part in [\"-\", \",\", \"(\", \")\"]:\n",
    "                number_parts.append(part)\n",
    "            else:\n",
    "                # If we haven't started collecting numbers, it's part of street\n",
    "                if not number_parts:\n",
    "                    street_parts.append(part)\n",
    "                else:\n",
    "                    # If we have numbers but encounter text, it might be descriptive\n",
    "                    number_parts.append(part)\n",
    "\n",
    "        street = \" \".join(street_parts)\n",
    "        numbers = \" \".join(number_parts)\n",
    "\n",
    "    return {\n",
    "        \"PNA\": postal_code,\n",
    "        \"MiejscowoÅ›Ä‡\": locality,\n",
    "        \"Ulica\": street,\n",
    "        \"Numery\": numbers,\n",
    "        \"Gmina\": gmina,\n",
    "        \"Powiat\": powiat,\n",
    "        \"WojewÃ³dztwo\": voivodeship,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Row parsing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the first few pages\n",
    "def parse_pdf_pages(\n",
    "    pdf_path: str, start_page: int = 2, end_page: int = None\n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"Parse PDF pages and extract postal code data\"\"\"\n",
    "    results = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        total_pages = len(pdf.pages)\n",
    "\n",
    "        if end_page is None:\n",
    "            end_page = total_pages\n",
    "\n",
    "        print(f\"Processing pages {start_page} to {end_page} of {total_pages}\")\n",
    "\n",
    "        for page_num in range(\n",
    "            start_page - 1, min(end_page, total_pages)\n",
    "        ):  # Convert to 0-based indexing\n",
    "            page = pdf.pages[page_num]\n",
    "            print(f\"Processing page {page_num + 1}\")\n",
    "\n",
    "            try:\n",
    "                # Extract all text from the page\n",
    "                text = page.extract_text()\n",
    "\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                # Split into lines\n",
    "                lines = text.split(\"\\n\")\n",
    "\n",
    "                for line in lines:\n",
    "                    line = clean_text(line)\n",
    "                    if not line:\n",
    "                        continue\n",
    "\n",
    "                    # Skip header/footer lines\n",
    "                    if any(\n",
    "                        keyword in line\n",
    "                        for keyword in [\n",
    "                            \"Poczta Polska\",\n",
    "                            \"Strona\",\n",
    "                            \"Copyright\",\n",
    "                            \"PNA MiejscowoÅ›Ä‡ Ulica\",\n",
    "                        ]\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    # Try to parse as data row\n",
    "                    parsed_row = parse_row_columns(line)\n",
    "                    if parsed_row:\n",
    "                        results.append(parsed_row)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing page {page_num + 1}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"PDF parsing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the sample PDF (pages 3-22)\n",
    "pdf_path = \"pages_3_to_22.pdf\"\n",
    "\n",
    "# Parse the test pages\n",
    "print(\"Starting to parse PDF...\")\n",
    "data = parse_pdf_pages(pdf_path, start_page=1, end_page=5)  # Test with first 5 pages\n",
    "\n",
    "print(f\"\\nExtracted {len(data)} records\")\n",
    "\n",
    "# Show first few records\n",
    "if data:\n",
    "    print(\"\\nFirst 10 records:\")\n",
    "    for i, record in enumerate(data[:10]):\n",
    "        print(f\"{i+1:2d}. {record}\")\n",
    "else:\n",
    "    print(\"No data extracted. Let's debug...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the above didn't work, let's try a different approach\n",
    "# Let's examine the raw text structure first\n",
    "\n",
    "\n",
    "def debug_page_structure(pdf_path: str, page_num: int = 1):\n",
    "    \"\"\"Debug the structure of a specific page\"\"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_num - 1]  # Convert to 0-based\n",
    "\n",
    "        print(f\"=== PAGE {page_num} DEBUG ===\")\n",
    "\n",
    "        # Extract raw text\n",
    "        text = page.extract_text()\n",
    "        lines = text.split(\"\\n\")\n",
    "\n",
    "        print(f\"Total lines: {len(lines)}\\n\")\n",
    "\n",
    "        # Show first 20 lines\n",
    "        for i, line in enumerate(lines[:20]):\n",
    "            line_clean = clean_text(line)\n",
    "            postal_match = (\n",
    "                is_postal_code(line_clean.split()[0]) if line_clean.split() else False\n",
    "            )\n",
    "            print(\n",
    "                f\"{i+1:2d}: {'[POSTAL]' if postal_match else '[-----]'} {repr(line_clean[:100])}\"\n",
    "            )\n",
    "\n",
    "\n",
    "# Debug the first page\n",
    "debug_page_structure(pdf_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the debug output, let's refine our parsing approach\n",
    "\n",
    "\n",
    "def improved_parse_row(line: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"Improved row parsing based on observed structure\"\"\"\n",
    "    line = clean_text(line)\n",
    "\n",
    "    if not line:\n",
    "        return None\n",
    "\n",
    "    # Skip obvious non-data lines\n",
    "    skip_patterns = [\n",
    "        \"Poczta Polska\",\n",
    "        \"Oficjalny Spis\",\n",
    "        \"Strona\",\n",
    "        \"Copyright\",\n",
    "        \"PNA MiejscowoÅ›Ä‡\",\n",
    "        \"CzÄ™Å›Ä‡ 1\",\n",
    "        \"miejscowoÅ›ci i ulic\",\n",
    "    ]\n",
    "\n",
    "    if any(pattern in line for pattern in skip_patterns):\n",
    "        return None\n",
    "\n",
    "    # Split by whitespace but preserve some structure\n",
    "    parts = line.split()\n",
    "\n",
    "    if len(parts) < 4:\n",
    "        return None\n",
    "\n",
    "    # First part must be postal code\n",
    "    if not is_postal_code(parts[0]):\n",
    "        return None\n",
    "\n",
    "    postal_code = parts[0]\n",
    "\n",
    "    # The challenge is that voivodeships, powiats, and gminas can be compound words\n",
    "    # Let's work backwards from known voivodeships\n",
    "    voivodeships = [\n",
    "        \"mazowieckie\",\n",
    "        \"Å›lÄ…skie\",\n",
    "        \"wielkopolskie\",\n",
    "        \"maÅ‚opolskie\",\n",
    "        \"lubelskie\",\n",
    "        \"podkarpackie\",\n",
    "        \"dolnoÅ›lÄ…skie\",\n",
    "        \"kujawsko-pomorskie\",\n",
    "        \"pomorskie\",\n",
    "        \"Å‚Ã³dzkie\",\n",
    "        \"zachodniopomorskie\",\n",
    "        \"lubuskie\",\n",
    "        \"podlaskie\",\n",
    "        \"Å›wiÄ™tokrzyskie\",\n",
    "        \"opolskie\",\n",
    "        \"warmiÅ„sko-mazurskie\",\n",
    "    ]\n",
    "\n",
    "    # Find voivodeship (should be last or near last)\n",
    "    voivodeship = \"\"\n",
    "    voiv_idx = -1\n",
    "\n",
    "    for i in range(len(parts) - 1, -1, -1):\n",
    "        if parts[i] in voivodeships:\n",
    "            voivodeship = parts[i]\n",
    "            voiv_idx = i\n",
    "            break\n",
    "        # Also check for compound voivodeships\n",
    "        if i > 0:\n",
    "            compound = parts[i - 1] + \"-\" + parts[i]\n",
    "            if compound in voivodeships:\n",
    "                voivodeship = compound\n",
    "                voiv_idx = i - 1\n",
    "                break\n",
    "\n",
    "    if not voivodeship:\n",
    "        return None\n",
    "\n",
    "    # Powiat should be before voivodeship\n",
    "    powiat = \"\"\n",
    "    powiat_idx = voiv_idx - 1\n",
    "\n",
    "    if voivodeship.count(\"-\") > 0:  # Compound voivodeship\n",
    "        powiat_idx = voiv_idx - 1\n",
    "\n",
    "    if powiat_idx >= 1:\n",
    "        powiat = parts[powiat_idx]\n",
    "\n",
    "    # Gmina should be before powiat\n",
    "    gmina = \"\"\n",
    "    gmina_idx = powiat_idx - 1\n",
    "\n",
    "    if gmina_idx >= 1:\n",
    "        gmina = parts[gmina_idx]\n",
    "\n",
    "    # Everything between postal code and gmina is locality/street/numbers\n",
    "    middle_parts = parts[1:gmina_idx]\n",
    "\n",
    "    if not middle_parts:\n",
    "        return None\n",
    "\n",
    "    # First middle part is locality\n",
    "    locality = middle_parts[0]\n",
    "\n",
    "    # Remaining parts are street and numbers\n",
    "    street_parts = []\n",
    "    number_parts = []\n",
    "\n",
    "    collecting_numbers = False\n",
    "    for part in middle_parts[1:]:\n",
    "        # If it looks like numbers/ranges, collect as numbers\n",
    "        if (\n",
    "            re.search(r\"^\\d\", part)\n",
    "            or part in [\"-\", \",\", \"(\", \")\", \"n\", \"p\"]\n",
    "            or collecting_numbers\n",
    "        ):\n",
    "            number_parts.append(part)\n",
    "            collecting_numbers = True\n",
    "        else:\n",
    "            if not collecting_numbers:\n",
    "                street_parts.append(part)\n",
    "\n",
    "    return {\n",
    "        \"PNA\": postal_code,\n",
    "        \"MiejscowoÅ›Ä‡\": locality,\n",
    "        \"Ulica\": \" \".join(street_parts),\n",
    "        \"Numery\": \" \".join(number_parts),\n",
    "        \"Gmina\": gmina,\n",
    "        \"Powiat\": powiat,\n",
    "        \"WojewÃ³dztwo\": voivodeship,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Improved parsing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the improved parser\n",
    "def test_improved_parser(pdf_path: str, num_pages: int = 3):\n",
    "    \"\"\"Test the improved parser on a few pages\"\"\"\n",
    "    results = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num in range(min(num_pages, len(pdf.pages))):\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            lines = text.split(\"\\n\")\n",
    "\n",
    "            for line_num, line in enumerate(lines):\n",
    "                parsed = improved_parse_row(line)\n",
    "                if parsed:\n",
    "                    results.append(parsed)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test the improved parser\n",
    "print(\"Testing improved parser...\")\n",
    "test_data = test_improved_parser(pdf_path, 3)\n",
    "\n",
    "print(f\"\\nExtracted {len(test_data)} records\")\n",
    "\n",
    "if test_data:\n",
    "    print(\"\\nFirst 15 records:\")\n",
    "    for i, record in enumerate(test_data[:15]):\n",
    "        print(\n",
    "            f\"{i+1:2d}. {record['PNA']} | {record['MiejscowoÅ›Ä‡']:20} | {record['Ulica']:20} | {record['Numery']:15} | {record['Gmina']:15} | {record['Powiat']:15} | {record['WojewÃ³dztwo']}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Still no data. Let's examine specific lines...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}